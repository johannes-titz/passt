---
title: "A too short introduction to PASS-T with the *passt* R package"
author: "Johannes Titz (johannes.titz at gmail.com)"
date: "`r Sys.Date()`"
bibliography: "library.bib"
csl: apa.csl
output: 
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.height=3.5, fig.width=5,
                      fig.align = "center")
```

The *passt* package is an R implementation of the PASS-T model, an artificial neural network designed to explain how humans make judgments of frequency and duration. The package was developed with two purposes in mind: (1) to provide a simple way to reproduce simulation results in judgments of frequency and duration as described in @Titz2019 and (2) to explore the PASS-T model by running individual simulations on your own.

The general idea of the original PASS model [@Sedlmeier1999;@Sedlmeier2002a] is that information about the frequency of events is naturally incorporated in artificial neural networks. I an object is presented repeatedely the weights of the network change in a systematic way. This way, the network is able to deduce the frequency of occurence of events based on the final weights. Put simply, the artificial neural produces a higher activation if a stimulus was presented more often

As an extension of the PASS model, PASS-T (T for time) is also able to process the presentation time of stimuli. One can define how often and how long different objects are presented and test whether the network is able to make valid judgments of frequency and duration in retrospect. The main aim of PASS-T is to explain (1) why the relationship between exposure frequency and the judgment is usually larger than between exposure duration and the judgment and (2) how attention affects these relationships.

Empirical work accompanying the PASS-T model can be found in @Titz2018. To fully understand this vignette it makes sense to also read the article on the PASS-T model [@Titz2019].

# Using *passt*
There are only two functions you will need to use from *passt*. The first one is *run_sim*, which runs several simulations with specific parameters and returns the final output activation for each input pattern. The second is *run_exp* which aggregates the data and gives effect sizes for each simulation run. Let us first look at *run_sim*.

Since PASS-T extends the PASS model, PASS-T should be able to produce all results PASS can produce. The most simple PASS simulation corresponds with a counter: an artificial neural network sensitive only to frequency information.

## A simple counter
Let us first load the package and set a seed so that the results are reproducable:

```{r}
library(passt)
set.seed(20191015)
```

```{r}
sim1 <- run_sim(patterns = diag(10), frequency = 1:10, duration = 10:1,
                lrate_onset = 0.05, lrate_drop_time = 2, lrate_drop_perc = 0)
```

Some explanation is necessary: *patterns* is a matrix of input patterns that the network will process. Here we will use orthogonal stimuli to avoid any interference on the input level. The function *diag* will create an identity matrix so every input pattern has only one active unit; and this active unit will be unique for each pattern. You can also use other stimuli patterns as long as the activation for each unit is either 0 or 1. 

Next, we specifiy how often the ten patterns should be shown and the duration of each presentation. The first pattern will be shown once for 10~s, the second pattern will be shown twice for 9~s each (a total duration of 18~s) and so on. You can also use other constellation for a simple counter.

Finally, we set the learning rate parameters: the initial learning rate (*lrate_onset*) is 0.05, but after 2~s (*lrate_drop_time*) it wil drop to 0 (*lrate_drop_perc*). This parameter selection is crucial for a counter because only the first second of a stimulus presentation is processed by the network.

The function *run_sim* returns a list with three elements, of which *output* is the most interesting. Note that by default, 100 simulations are run (you can change this with the parameter *n_runs*). We will only look at the first couple of simulations:

```{r}
head(sim1$output)
```

The *output* gives the sum of the activity of all output units for the specific patterns for each simulation run. A row corresponds with one simulation and a column with one input pattern. Sometimes the output activation is referred to as the *memory strength* in an abstract sense. One can easily see that increasing the presentation frequency (i.e. going from the first to the tenth column) results in a higher *memory strength* (activation). Let us take the average for each frequency condition and plot them:

```{r}
plot(x = 1:10, y = colMeans(sim1$output), xlab = "Frequency [#]", ylab = "Activation",
     pch = 19)
```

We can also calculate the correlation between frequency and the activation for each simulation run and make a histogram:

```{r}
correlations <- apply(sim1$output, 1, function(x) cor(1:10, x))
hist(correlations)
```

Now, this is clearly a result that appears unrealistic because the correlations are much too high. A simulation that better fits empirical results should contain some noise. 

## A simple noisy counter
To add noise to our simulation we can use the function *run_exp*, which will also analyze the data for us and report effect sizes:

```{r warning=FALSE}
sim2 <- run_exp(patterns = diag(10), frequency = 1:10,
                duration = 10:1,
                lrate_onset = 0.05, lrate_drop_time = 2,
                lrate_drop_perc = 0, cor_noise_sd = 0.1)
```

The only new parameter is *cor_noise_sd* which introduces Gaussain noise in the system with the corresponding standard deviation around a mean of 0. Note that the function *run_exp* does not return the individual input patterns, but aggregates the data on the simulation level:

```{r}
sim2
```

*f_dv* is the correlation between frequency and the dependent variable, which is just the output activation. The effect is 0.75, which much better fits the empirical findings than the result of our first simulation (where the correlation was 1). *td_dv* is the correlation between total duration ($f\times d$) and the dependent variable and *d_dv* is the correlation between single duration and the dependent variable. 

Note that the independent variables of frequency and duration are negatively correlated and thus *f_dv* and *d_dv* are identical in absolute size. In a proper experiment this is what we want because total duration and frequency should be independent. It is not possible to make all three variables (frequency, duration, total duration) independent. Based on theoretical arguments, it makes more sense to make frequency and total duration independent [e.g., @Betsch2010]. This is the case here and the counter seems to work: only the exposure frequency affects the *memory strength* of the network, but not the total presentation duration.

The reason for the strong effect of frequency is that the learning rate of the network drops to 0 (*lrate_drop_perc*) at 2 s (*lrate_drop_time*). Intuitively this means that the network only process an appearing stimulus for a short time (here 2 s) and then processing shuts down. This is the main mechanism to explain why frequency is the dominant factor in judgments of frequency and duration [Titz2018,Titz2019].

But it has also been argued that under certain circumstances the learning rate does not drop to 0. For instance, @Betsch2010 found that interesting material and special instructions led to a much larger effects of exposure duration on judgments, which would mean that the learning rate remained above 0 after 2 s. To implement this in a simulation, we need to vary the parameter *lrate_drop_perc* which influences how much the learning rate (or attention) diminishes as a percentage of the initial learning rate. Conceptually the parameter *lrate_drop_perc* is directly related to the the construct attention [@Titz2019]. In the final simulation we will try to investiagte how "attention" affects effect sizes.

## Simulating the moderating role of attention
Since @Betsch2010 studied the effects of attention on jdugments of frequency and duration, we can directly use their values for the orthogonal independent variables of frequency and total duration:

```{r}
duration <- c(4, 2, 1, 8, 4, 2, 12, 6, 3)
frequency <- c(2, 4, 8, 2, 4, 8, 2, 4, 8)
total_duration = frequency * duration
cor(frequency, total_duration)
```

And now the simulation:

```{r}
lrate_drop_perc <- seq(0, 1, 0.04)
sim4 <- lapply(lrate_drop_perc, function(x) 
  run_exp(duration, frequency, 0.05, 2, x, diag(9), 30, 0.1))
```

The *lapply* function goes through each *lrate_drop_perc* value and runs a simulation. Note that we reduced the number of simulation runs to 10 to keep the computation time in check. Since we now have a list of simulations, we need to make it into  a data frame first and also add the information about the drop of the learning parameter:

```{r}
sim4 <- plyr::ldply(sim4, "data.frame")
sim4 <- cbind(sim4, lrate_drop_perc)
sim4
```

If the learning rate does not drop much (i.e. *lrate_drop_perc* values close to 1), the influence of total duration (*td_dv*) on the output activation is strong, while the influence of frequency (*f_dv*) is weak. But if the learning rate drops substantially (i.e. *lrate_drop_perc* values close to 0), the opposite is true. 

A plot might help to understand what is difficult to put in words here. Since the relationship is somewhat complicated we will use the power of grammar of graphics (ggplot2):

```{r fig.height=3.5, fig.width=5, warning=FALSE}
library(ggplot2)
ggplot(sim4, aes(f_dv, td_dv, color = lrate_drop_perc*100)) +
  geom_point(alpha = 1) +
  guides(color = guide_colorbar(order=1)) +
  scale_color_gradient(name = "Learning parameter drop [%]", low = "grey90",
                        high = "black", breaks = seq(0, 100, 25)) +
  theme_bw() +

  theme(legend.position = c(0, 1),
        legend.justification = c(0, 1),
        legend.direction = "horizontal",
        legend.background = element_rect(fill=alpha('white', 0.3))) +
  scale_x_continuous(name = "Influence of frequency", limits = c(-.1, 1)) +
  scale_y_continuous("Influence of duration", limits = c(-.1, 1))
```

And here we can clearly see that the effects of exposure frequency and exposure duration depend on how much the learning parameter drops. Intuitively we could say that if the "attention" of the network remains high all the time (learning rate remains at 100%), the effect of duration is weak, while the effect of frequency is strong. But under normal experimental conditions, the assumption is that attention drops substantially shortly after the onset of a stimulus [@Titz2018]. Thus, the influence of frequency is very strong, but the influence of duration is weak. This arrangement is sometimes referred to as *frequency primacy*.

This was only a very short or an even *too* short introduction to PASS-T via *passt*. If you are interested in the model, please check out our publications: @Titz2019,@Titz2018. Any feedback is very welcome, just drop me an e-mail at johannes.titz at gmail.com or file an issue at github: github/johannes-titz/passt

# References
